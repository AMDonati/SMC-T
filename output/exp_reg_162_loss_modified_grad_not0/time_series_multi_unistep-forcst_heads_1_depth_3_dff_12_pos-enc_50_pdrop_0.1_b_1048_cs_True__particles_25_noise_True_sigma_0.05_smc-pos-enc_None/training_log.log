INFO:training log:model hyperparameters from the config file: {'num_layers': 1, 'num_heads': 1, 'd_model': 3, 'dff': 12, 'rate': 0.1, 'maximum_position_encoding_baseline': 50, 'maximum_position_encoding_smc': 'None'}
INFO:training log:smc hyperparameters from the config file: {'num_particles': 25, 'noise_encoder': 'False', 'noise_SMC_layer': 'True', 'sigma': 0.05}
INFO:training log:starting the training of the smc transformer...
INFO:training log:number of training samples: 336290
INFO:training log:steps per epoch: 320
WARNING:tensorflow:Layer smc__transformer is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

INFO:training log:Epoch 1/30
INFO:training log:final weights of first 3 elements of batch: [0.04020952 0.04011144 0.0400178  0.03983272 0.03998684 0.04014169
 0.03981902 0.04021563 0.04021934 0.03988078 0.03989452 0.03968048
 0.03990681 0.03980606 0.04003273 0.03990543 0.04032391 0.03959725
 0.04005431 0.04010352 0.0401037  0.04022921 0.04010596 0.03996151
 0.03985975], [0.04157915 0.04044935 0.04179864 0.03900035 0.0418514  0.04079068
 0.04046629 0.03849748 0.04098525 0.04079764 0.04009435 0.04121655
 0.04143899 0.03883698 0.03884448 0.03568821 0.04072999 0.03687505
 0.04143965 0.03968578 0.04094643 0.04232277 0.03996808 0.03857207
 0.03712443], [0.03997767 0.03964588 0.04012044 0.03983669 0.04012122 0.04005679
 0.04010426 0.04008094 0.04023681 0.03986906 0.04005897 0.0399612
 0.03992144 0.0401549  0.04012223 0.03984841 0.04008574 0.04000061
 0.04000524 0.03987544 0.03992934 0.0398147  0.03997659 0.04021882
 0.0399766 ]
INFO:training log:train loss 6.905702590942383 -  train mse loss: 0.9064759612083435 - val loss: 6.7057366371154785 - val mse loss: 0.7071146368980408
INFO:training log:Time taken for 1 epoch: 2469.3271164894104 secs

INFO:training log:Epoch 2/30
INFO:training log:final weights of first 3 elements of batch: [0.04023006 0.04016903 0.03979493 0.03994492 0.04012472 0.04016486
 0.04024929 0.0396769  0.04014547 0.04010872 0.03962825 0.04000416
 0.04008495 0.0399957  0.03996245 0.0400263  0.04013224 0.03980976
 0.04019931 0.03962389 0.04026276 0.03991568 0.03981948 0.03980947
 0.04011674], [0.04035484 0.04019548 0.04021296 0.04009458 0.03981912 0.04075044
 0.0396945  0.03913326 0.04072478 0.03963566 0.04045804 0.03862952
 0.04004927 0.03973788 0.04015679 0.04075158 0.04012465 0.04076513
 0.03950637 0.03933105 0.03945966 0.0395929  0.04031151 0.04038669
 0.04012331], [0.04051079 0.04029083 0.03975403 0.04142009 0.04044628 0.04002905
 0.04021519 0.04047128 0.03919135 0.04017026 0.04004318 0.03970951
 0.04052395 0.04002217 0.03973681 0.041313   0.03925264 0.04034099
 0.04043901 0.0391332  0.03848606 0.03988668 0.03864106 0.03926547
 0.0407072 ]
INFO:training log:train loss 6.248542308807373 -  train mse loss: 0.24769894778728485 - val loss: 6.163980007171631 - val mse loss: 0.16707748174667358
INFO:training log:Time taken for 1 epoch: 2507.358862876892 secs

INFO:training log:Epoch 3/30
INFO:training log:final weights of first 3 elements of batch: [0.04008253 0.03983074 0.0400066  0.03935317 0.03982769 0.04005286
 0.04006954 0.04015751 0.03991546 0.04021272 0.03998966 0.03975591
 0.04006376 0.04015369 0.03992721 0.03970491 0.0401422  0.04014715
 0.04024458 0.04006257 0.04012448 0.04014518 0.04004091 0.03984481
 0.04014412], [0.04026197 0.04045108 0.0397361  0.04024146 0.04001105 0.03988345
 0.03999497 0.03960027 0.0399163  0.03983665 0.03898243 0.03976684
 0.0405444  0.04006639 0.04013425 0.03990521 0.03995709 0.04004091
 0.03980666 0.04015685 0.03998752 0.04012692 0.0402059  0.0399805
 0.04040477], [0.03809314 0.04105604 0.04098155 0.04081183 0.04009622 0.04022383
 0.04016256 0.03900116 0.03856342 0.03827899 0.03897693 0.04068301
 0.03941046 0.04257015 0.03782859 0.03871775 0.04252783 0.04039731
 0.04090869 0.03782885 0.04051058 0.03969722 0.04021552 0.04022397
 0.04223451]
INFO:training log:train loss 6.081523895263672 -  train mse loss: 0.07954438030719757 - val loss: 6.030803203582764 - val mse loss: 0.03086189739406109
INFO:training log:Time taken for 1 epoch: 2508.2653470039368 secs

INFO:training log:Epoch 4/30
INFO:training log:final weights of first 3 elements of batch: [0.03991398 0.04007167 0.04003942 0.04009274 0.0400983  0.04006974
 0.039996   0.04000146 0.04007161 0.03992352 0.04003672 0.0399766
 0.03993487 0.03996045 0.0400846  0.04009866 0.0400495  0.04009521
 0.03997378 0.03971166 0.03998547 0.04009635 0.03986829 0.04000888
 0.03984056], [0.04080562 0.04027709 0.04016947 0.03962992 0.04011091 0.04035686
 0.03944349 0.04077848 0.03868809 0.04105579 0.04111709 0.03885338
 0.03853528 0.03990799 0.03888316 0.0391775  0.04105628 0.03825982
 0.04073061 0.03883772 0.04130421 0.04054258 0.04008522 0.04089108
 0.04050237], [0.03763593 0.03841301 0.03698157 0.04046163 0.0430747  0.04022083
 0.04118389 0.04197127 0.0421208  0.04247054 0.04374157 0.03997672
 0.03812148 0.03581213 0.04016608 0.03820052 0.04007763 0.03901191
 0.04327377 0.03818799 0.04027482 0.04242653 0.04084146 0.03483274
 0.04052053]
INFO:training log:train loss 6.01641321182251 -  train mse loss: 0.01973211206495762 - val loss: 6.005688190460205 - val mse loss: 0.010106449015438557
INFO:training log:Time taken for 1 epoch: 2429.8395960330963 secs

INFO:training log:Epoch 5/30
INFO:training log:final weights of first 3 elements of batch: [0.04003247 0.04011371 0.0401088  0.03997434 0.03986336 0.04007045
 0.04007255 0.03985195 0.04001505 0.04005441 0.04011369 0.0400999
 0.04003707 0.04010544 0.03975201 0.04005991 0.0397756  0.03991267
 0.04003006 0.04011409 0.03975237 0.0399251  0.04003463 0.0400307
 0.0400997 ], [0.03949437 0.03843273 0.04121465 0.04084967 0.040278   0.03948695
 0.04055253 0.03901143 0.04113826 0.03949951 0.03989321 0.04044496
 0.04078204 0.03944186 0.04095228 0.04050474 0.03867376 0.03993276
 0.04013728 0.039984   0.04023674 0.03982142 0.04017443 0.04003799
 0.03902448], [0.0374766  0.03859619 0.04029118 0.04030304 0.03873047 0.03788276
 0.04188899 0.04206882 0.04078861 0.04226307 0.03634044 0.04137685
 0.04056267 0.04145754 0.04018728 0.04124951 0.03886773 0.03877065
 0.0409938  0.03984626 0.03764117 0.04000406 0.04183595 0.03946789
 0.04110848]
INFO:training log:train loss 6.0059943199157715 -  train mse loss: 0.008397758938372135 - val loss: 6.0106096267700195 - val mse loss: 0.006587812211364508
INFO:training log:Time taken for 1 epoch: 2377.3411257267 secs

INFO:training log:Epoch 6/30
INFO:training log:final weights of first 3 elements of batch: [0.03991039 0.03995396 0.04005671 0.03999122 0.04004499 0.03999627
 0.04007037 0.0400337  0.0399782  0.03995516 0.03985566 0.04005976
 0.04007603 0.03993751 0.0399522  0.03989473 0.04003038 0.04000136
 0.04005316 0.03999838 0.04003543 0.04002488 0.04007614 0.03998578
 0.04002761], [0.04000837 0.03924642 0.04024013 0.03882197 0.0404164  0.04078976
 0.03909036 0.03906111 0.04056953 0.04015508 0.04077781 0.04017244
 0.04022269 0.04054885 0.0401422  0.03957517 0.04058331 0.04056875
 0.03911645 0.04040514 0.0402349  0.03903864 0.03948169 0.04038727
 0.04034556], [0.03952152 0.04134597 0.04021191 0.04056465 0.03797231 0.04205146
 0.04108394 0.04254499 0.03841186 0.04089567 0.04115629 0.03957924
 0.03896594 0.03864286 0.03956    0.04161111 0.04048171 0.03887155
 0.0392999  0.03613748 0.04078654 0.03978593 0.03979384 0.04087364
 0.03984964]
INFO:training log:train loss 6.011198043823242 -  train mse loss: 0.006370394956320524 - val loss: 6.003260612487793 - val mse loss: 0.0052362363785505295
INFO:training log:Time taken for 1 epoch: 2379.632812023163 secs

INFO:training log:Epoch 7/30
INFO:training log:final weights of first 3 elements of batch: [0.04009194 0.04005546 0.04010115 0.03994325 0.04005919 0.04007244
 0.04006924 0.03995185 0.03977274 0.04012476 0.04000747 0.03994685
 0.0401093  0.03997122 0.03998972 0.03977669 0.04011673 0.03998879
 0.04003749 0.03983624 0.04002701 0.03997676 0.04006124 0.03995893
 0.03995358], [0.04068464 0.0395463  0.04038734 0.03960389 0.04018032 0.04067349
 0.03967807 0.04020969 0.0397353  0.03995221 0.04017387 0.03952516
 0.03895906 0.03973474 0.03993218 0.04031498 0.04019284 0.04075897
 0.04017132 0.03983105 0.03904467 0.04077066 0.04010123 0.039804
 0.04003398], [0.04018534 0.03857062 0.04098309 0.03768218 0.0413451  0.03885057
 0.03948749 0.0376842  0.03838333 0.03994848 0.03872754 0.04006226
 0.03948367 0.04346098 0.03942924 0.03926271 0.04061853 0.04064236
 0.04072738 0.04191479 0.04093656 0.03951423 0.03931325 0.04134969
 0.04143639]
INFO:training log:train loss 6.0028886795043945 -  train mse loss: 0.0059228381142020226 - val loss: 6.00824499130249 - val mse loss: 0.004401498008519411
INFO:training log:Time taken for 1 epoch: 2374.0042605400085 secs

INFO:training log:Epoch 8/30
INFO:training log:final weights of first 3 elements of batch: [0.0399221  0.04004889 0.04003024 0.03999322 0.04001513 0.03999963
 0.03994271 0.0400179  0.03997488 0.04006004 0.0399433  0.04004752
 0.0399073  0.03999995 0.04003648 0.03992493 0.04004883 0.04007673
 0.03993156 0.04002266 0.04000057 0.04003242 0.03992274 0.04007764
 0.04002266], [0.04091952 0.04011529 0.04043338 0.04021982 0.03993397 0.03998163
 0.03948952 0.03964298 0.03982244 0.0394045  0.03951865 0.04004453
 0.04035613 0.0400776  0.04019294 0.03985915 0.0397001  0.04020267
 0.04066938 0.03959318 0.04005777 0.03926539 0.04021121 0.03974655
 0.04054172], [0.03995934 0.03945393 0.04057978 0.03976682 0.04043479 0.0400955
 0.04096239 0.04238261 0.04037931 0.03785067 0.03915809 0.03891769
 0.04200731 0.04048103 0.04031504 0.04214625 0.03863173 0.0371735
 0.03845958 0.04054803 0.04156153 0.03971606 0.04070777 0.03897646
 0.03933476]
INFO:training log:train loss 6.0078816413879395 -  train mse loss: 0.005122189875692129 - val loss: 6.004553318023682 - val mse loss: 0.004170408472418785
INFO:training log:Time taken for 1 epoch: 2374.615413427353 secs

INFO:training log:Epoch 9/30
INFO:training log:final weights of first 3 elements of batch: [0.03994216 0.03995011 0.03972222 0.04010323 0.04011125 0.04003036
 0.04006853 0.04003602 0.04010101 0.04011456 0.03997069 0.04002754
 0.03991757 0.0400729  0.04001075 0.04007047 0.04000098 0.04005571
 0.04006793 0.04000033 0.03986173 0.03980789 0.03991401 0.04007952
 0.0399625 ], [0.04013154 0.04009005 0.03952492 0.04047989 0.04050094 0.03998191
 0.03951186 0.03973274 0.03958359 0.03954312 0.04040232 0.03953381
 0.04025061 0.03960232 0.03978124 0.04018193 0.04002836 0.03996503
 0.03959338 0.04023171 0.04008588 0.040231   0.03993416 0.04058667
 0.04051108], [0.03950175 0.04028621 0.03992992 0.04034315 0.03981378 0.04210634
 0.04021484 0.03966658 0.04056533 0.03954899 0.04081504 0.04111034
 0.04254518 0.04016887 0.03941915 0.03967241 0.03784897 0.03929147
 0.04003412 0.0378217  0.03957141 0.03976409 0.04104942 0.03913699
 0.03977394]
INFO:training log:train loss 6.007892608642578 -  train mse loss: 0.0050282650627195835 - val loss: 6.002281188964844 - val mse loss: 0.003834699746221304
INFO:training log:Time taken for 1 epoch: 2372.8976497650146 secs

INFO:training log:Epoch 10/30
INFO:training log:final weights of first 3 elements of batch: [0.04009247 0.03985908 0.04008472 0.04006209 0.04004867 0.03989677
 0.03974976 0.04004683 0.0400297  0.04009666 0.04007063 0.03993692
 0.04010651 0.04007629 0.03990113 0.03993127 0.03987741 0.04008199
 0.03995194 0.04007773 0.04004762 0.04009526 0.04002726 0.0399664
 0.03988485], [0.04008083 0.04005209 0.03970791 0.03958581 0.04014848 0.04003363
 0.04036855 0.04012438 0.04025155 0.04048811 0.03996418 0.04009049
 0.03957467 0.04022016 0.04020319 0.03992304 0.04045539 0.03920958
 0.04055221 0.03986667 0.03972875 0.03942495 0.04044339 0.03956653
 0.03993547], [0.03986769 0.03978743 0.04100447 0.04000251 0.03750324 0.0390102
 0.03904435 0.04040318 0.03930089 0.04121521 0.04135254 0.04177344
 0.04055692 0.03905097 0.04075818 0.03934654 0.04043729 0.04017141
 0.04071084 0.04038153 0.03985127 0.03812452 0.04042695 0.04060325
 0.03931516]
INFO:training log:train loss 6.004347801208496 -  train mse loss: 0.004588391166180372 - val loss: 6.006111145019531 - val mse loss: 0.003581876400858164
INFO:training log:Time taken for 1 epoch: 2378.4853167533875 secs

INFO:training log:Epoch 11/30
INFO:training log:final weights of first 3 elements of batch: [0.04004192 0.04004845 0.03993489 0.0400483  0.04003834 0.03996735
 0.03991742 0.04000928 0.0400173  0.03988632 0.03998743 0.04005008
 0.04002584 0.04004004 0.04004389 0.04000209 0.04004942 0.04004677
 0.03994906 0.04000392 0.03996417 0.03996219 0.03994279 0.04004565
 0.03997717], [0.03993551 0.04008431 0.04027629 0.04014408 0.03938746 0.04024643
 0.04049631 0.04013711 0.03970142 0.03966569 0.03985375 0.03962606
 0.03952103 0.03988664 0.04023336 0.04059429 0.03941105 0.03954198
 0.04029297 0.04025927 0.03962576 0.04044518 0.04025322 0.04022128
 0.04015952], [0.03811534 0.04028092 0.04114439 0.04157266 0.03926454 0.04057688
 0.03972321 0.03886393 0.0402371  0.04089603 0.03931479 0.03901847
 0.03924202 0.04021207 0.03865435 0.03840679 0.03926412 0.03986589
 0.04185906 0.04097012 0.04112828 0.0401802  0.040057   0.04073624
 0.04041561]
INFO:training log:train loss 6.004151821136475 -  train mse loss: 0.004548180382698774 - val loss: 6.0037431716918945 - val mse loss: 0.003481614636257291
INFO:training log:Time taken for 1 epoch: 2368.7828493118286 secs

INFO:training log:Epoch 12/30
INFO:training log:final weights of first 3 elements of batch: [0.0400492  0.03988602 0.03999804 0.0400079  0.04003957 0.04001437
 0.04007229 0.03983685 0.04008109 0.03998921 0.04005969 0.03999254
 0.04001014 0.03998588 0.03997954 0.03997545 0.04006547 0.04001452
 0.03997455 0.03988857 0.04004939 0.03995247 0.04009057 0.04000396
 0.03998269], [0.03989685 0.03983226 0.03994538 0.04012463 0.03987469 0.04010378
 0.04037122 0.04052755 0.04012447 0.03958174 0.03977625 0.04035558
 0.04017895 0.03983602 0.04018088 0.03981525 0.04018643 0.04017199
 0.0395666  0.03960276 0.03950169 0.04008227 0.04028837 0.04026617
 0.03980817], [0.03970626 0.03955079 0.03980456 0.04069944 0.04083445 0.04134363
 0.04147676 0.04140558 0.0400204  0.03925228 0.04123269 0.03982753
 0.04042168 0.03888334 0.03886665 0.03901394 0.03911427 0.03884473
 0.04004989 0.04018538 0.04018536 0.04074822 0.03997751 0.03995167
 0.03860299]
INFO:training log:train loss 6.006082534790039 -  train mse loss: 0.004278700798749924 - val loss: 6.004670143127441 - val mse loss: 0.0033695129677653313
INFO:training log:Time taken for 1 epoch: 2377.9554965496063 secs

INFO:training log:Epoch 13/30
INFO:training log:final weights of first 3 elements of batch: [0.0400435  0.04000271 0.0399768  0.03978647 0.04003345 0.04000842
 0.03996934 0.04002389 0.04003083 0.04001659 0.0400155  0.04003076
 0.04002701 0.04003176 0.0400144  0.0400313  0.03991728 0.04002812
 0.040006   0.03998494 0.03998825 0.04002957 0.03997813 0.03998123
 0.04004373], [0.04005888 0.03963813 0.04000107 0.04020843 0.04030165 0.04061088
 0.04000963 0.04024306 0.04002222 0.03977446 0.03936831 0.03982457
 0.03979241 0.03972572 0.03995048 0.03988007 0.040224   0.03969123
 0.03983932 0.0404722  0.03995914 0.04020414 0.04000715 0.03998456
 0.04020828], [0.03944925 0.04232472 0.04035344 0.04077244 0.03945233 0.03875272
 0.03817356 0.04004598 0.03911918 0.04000048 0.03983146 0.04073424
 0.03935136 0.03893421 0.04024399 0.04139645 0.04206076 0.03917777
 0.03992461 0.04011231 0.03999453 0.04000062 0.03929453 0.04003413
 0.04046484]
INFO:training log:train loss 5.998813152313232 -  train mse loss: 0.0043608397245407104 - val loss: 6.000243186950684 - val mse loss: 0.0032452913001179695
INFO:training log:Time taken for 1 epoch: 2380.9595668315887 secs

INFO:training log:Epoch 14/30
INFO:training log:final weights of first 3 elements of batch: [0.04004443 0.03997293 0.04002586 0.04000109 0.04002276 0.04003357
 0.03991535 0.03992167 0.03995114 0.04004982 0.04003171 0.040014
 0.03999347 0.03999017 0.03992904 0.03998109 0.04001895 0.03997514
 0.04004119 0.040009   0.03998799 0.04002756 0.04004563 0.04001521
 0.0400012 ], [0.039855   0.04046578 0.03994641 0.0398836  0.03986546 0.04010751
 0.03990398 0.0396621  0.03954453 0.03990191 0.04035432 0.03990962
 0.04001638 0.03990473 0.04002133 0.03971533 0.04017823 0.04026502
 0.03989811 0.04055206 0.03995817 0.03964302 0.04047453 0.04010992
 0.03986295], [0.04096136 0.041202   0.03994484 0.03899148 0.03916499 0.04180979
 0.04032554 0.03906046 0.03919027 0.04125171 0.03939766 0.04084587
 0.03939015 0.03985654 0.0411866  0.04012356 0.04055139 0.04005292
 0.03928615 0.03917479 0.04060596 0.03945516 0.03922972 0.03916121
 0.03977988]
INFO:training log:train loss 6.000133514404297 -  train mse loss: 0.0040721888653934 - val loss: 6.0071306228637695 - val mse loss: 0.003234496107324958
INFO:training log:Time taken for 1 epoch: 2380.0387766361237 secs

INFO:training log:Epoch 15/30
INFO:training log:final weights of first 3 elements of batch: [0.03995384 0.04006182 0.03997828 0.04006199 0.03983987 0.03999092
 0.0398311  0.0400691  0.03999281 0.04006503 0.04007415 0.04003643
 0.04006201 0.04004055 0.03999892 0.04003518 0.03997238 0.03999717
 0.03993958 0.03997661 0.03999409 0.04002642 0.0399853  0.04003856
 0.03997788], [0.03988892 0.04042742 0.04017741 0.04020063 0.04002694 0.04000867
 0.03999196 0.04023657 0.03981883 0.03993555 0.03999069 0.04019635
 0.03989474 0.03987653 0.03977057 0.0398202  0.04023306 0.04007993
 0.03996285 0.03997208 0.04021949 0.04008145 0.03925458 0.03965371
 0.04028084], [0.0417365  0.0399511  0.04030678 0.03869538 0.03990496 0.03975233
 0.03943329 0.03942705 0.03942177 0.04076671 0.03902745 0.04070427
 0.0405444  0.0393138  0.03948871 0.03962579 0.04160089 0.04045923
 0.04002954 0.04018605 0.03949713 0.04149015 0.03917352 0.03961011
 0.03985312]
INFO:training log:train loss 6.004604339599609 -  train mse loss: 0.004332806449383497 - val loss: 5.998998165130615 - val mse loss: 0.0031365160830318928
INFO:training log:Time taken for 1 epoch: 2378.3336651325226 secs

INFO:training log:Epoch 16/30
INFO:training log:final weights of first 3 elements of batch: [0.04000982 0.0399824  0.04000804 0.04002143 0.04004516 0.04001796
 0.03999491 0.04000845 0.04000637 0.04004216 0.04000941 0.04001624
 0.03997882 0.03991292 0.04003108 0.03998219 0.03999557 0.03998457
 0.04002447 0.03999191 0.03996254 0.03999827 0.04003005 0.03999667
 0.03994862], [0.03977021 0.03993374 0.03989839 0.04055941 0.03975115 0.03953867
 0.04031804 0.0401204  0.04015235 0.04044285 0.03995049 0.03992937
 0.03990188 0.04007921 0.04004548 0.03961996 0.03984748 0.04024565
 0.03999323 0.03990543 0.03998186 0.04032943 0.04007321 0.03976258
 0.03984956], [0.04127555 0.04003023 0.03998201 0.04015268 0.03867777 0.03970218
 0.03930411 0.04110729 0.040406   0.04041492 0.04030955 0.03932038
 0.04099802 0.03969994 0.04075833 0.03933032 0.0407     0.04037885
 0.04043464 0.03844001 0.03910416 0.03975379 0.0401323  0.0400259
 0.03956104]
INFO:training log:train loss 6.005581855773926 -  train mse loss: 0.004020398948341608 - val loss: 5.99992036819458 - val mse loss: 0.003044507233425975
INFO:training log:Time taken for 1 epoch: 2381.357965707779 secs

INFO:training log:Epoch 17/30
INFO:training log:final weights of first 3 elements of batch: [0.03995515 0.04003733 0.04003111 0.03999792 0.03996973 0.0399854
 0.03996646 0.03999554 0.04000605 0.04001328 0.04002451 0.04003277
 0.03998782 0.03997346 0.04003229 0.0400053  0.04001177 0.03999965
 0.0400302  0.03999783 0.04001854 0.03999567 0.04001727 0.03997682
 0.03993813], [0.03978572 0.03998021 0.04003138 0.04027246 0.03988005 0.04015421
 0.04006908 0.0398593  0.03970353 0.03962052 0.03995094 0.03968294
 0.03989008 0.03981245 0.04014021 0.03983688 0.04026028 0.03983001
 0.03988062 0.04025761 0.03981661 0.04059934 0.04002171 0.04043728
 0.04022656], [0.03972826 0.04012822 0.0401898  0.03993913 0.04134031 0.03945007
 0.03977895 0.04045077 0.04034233 0.03968997 0.04041472 0.04043851
 0.03892085 0.04000136 0.03879008 0.03955563 0.04104191 0.03952095
 0.0398693  0.04026927 0.04055041 0.04010371 0.0409321  0.03977598
 0.03877742]
INFO:training log:train loss 6.006448268890381 -  train mse loss: 0.0037800981663167477 - val loss: 5.998719215393066 - val mse loss: 0.003002075245603919
INFO:training log:Time taken for 1 epoch: 2375.7608585357666 secs

INFO:training log:Epoch 18/30
INFO:training log:final weights of first 3 elements of batch: [0.04002643 0.03999941 0.04001472 0.04002558 0.03997026 0.04001682
 0.04000901 0.04000693 0.03999696 0.04002918 0.04001412 0.04000567
 0.03988252 0.03999305 0.04002564 0.03997586 0.04001692 0.04003484
 0.04001711 0.03998964 0.04002351 0.03998063 0.03998477 0.03997937
 0.03998105], [0.04014411 0.03987367 0.0400724  0.04007552 0.03993957 0.03974999
 0.04017876 0.04014207 0.04017002 0.04001008 0.04024763 0.03973399
 0.03982501 0.0400805  0.03964702 0.03995307 0.03957881 0.03961439
 0.04026296 0.03974001 0.03986844 0.04045026 0.04032    0.04040248
 0.03991917], [0.03963816 0.04105665 0.03991177 0.04000401 0.03992219 0.03928751
 0.03957836 0.04043239 0.04011478 0.04076141 0.04020027 0.03984634
 0.04102931 0.03847068 0.03875345 0.03974877 0.03992214 0.04051012
 0.0400174  0.03944225 0.04086238 0.03916429 0.04012521 0.04013885
 0.04106128]
INFO:training log:train loss 6.0035600662231445 -  train mse loss: 0.0039978353306651115 - val loss: 5.999658107757568 - val mse loss: 0.002901417203247547
INFO:training log:Time taken for 1 epoch: 2378.4363691806793 secs

INFO:training log:Epoch 19/30
INFO:training log:final weights of first 3 elements of batch: [0.03994372 0.04003684 0.03998821 0.03998596 0.03993686 0.03998065
 0.03997518 0.04002728 0.03994687 0.04003753 0.03995881 0.04002122
 0.04003833 0.04002313 0.04003086 0.0399473  0.03997784 0.04001236
 0.04002537 0.04001686 0.03998936 0.04003871 0.03998787 0.04003628
 0.04003656], [0.03981833 0.0397656  0.04003459 0.0396422  0.03982366 0.0399184
 0.04049839 0.04004493 0.03987953 0.04015844 0.04006469 0.04018795
 0.04028508 0.03997573 0.0397944  0.04020684 0.03953418 0.03977005
 0.04020871 0.04042646 0.04038657 0.03972619 0.04024937 0.03986378
 0.03973598], [0.03982153 0.03959382 0.04045614 0.04137107 0.04054761 0.0400207
 0.03928933 0.04008713 0.04040155 0.04114247 0.03949678 0.03907197
 0.03863978 0.03996147 0.0407186  0.03971373 0.04077244 0.0403193
 0.03999049 0.04110303 0.04075328 0.03979279 0.03775059 0.03993657
 0.03924779]
INFO:training log:train loss 6.003834247589111 -  train mse loss: 0.003647265490144491 - val loss: 6.0043816566467285 - val mse loss: 0.0029265128541737795
INFO:training log:Time taken for 1 epoch: 2374.8302340507507 secs

INFO:training log:Epoch 20/30
INFO:training log:final weights of first 3 elements of batch: [0.03999022 0.04001828 0.04000471 0.04001033 0.0400035  0.040008
 0.03998557 0.04000135 0.03990249 0.0399901  0.04000963 0.04001237
 0.04002113 0.04002148 0.04001508 0.03999748 0.03998745 0.04000033
 0.04001965 0.03999898 0.03999595 0.04001736 0.04001034 0.04000685
 0.03997136], [0.03976726 0.03977754 0.03946332 0.03987465 0.04066239 0.04004874
 0.04036498 0.03972    0.04021279 0.04033389 0.03982607 0.04033798
 0.03995291 0.04042785 0.03976329 0.03952813 0.0401866  0.04015658
 0.03962232 0.03989844 0.04033169 0.03986685 0.04000597 0.04016988
 0.03969993], [0.03910569 0.03910781 0.04001197 0.04058442 0.03967838 0.03926945
 0.04144103 0.04077179 0.0414533  0.03995025 0.04061867 0.03958725
 0.0398783  0.03918649 0.03989855 0.04065188 0.03954523 0.03950175
 0.03950663 0.04051582 0.03970448 0.03908109 0.04018072 0.04036462
 0.04040444]
INFO:training log:train loss 6.0089802742004395 -  train mse loss: 0.003981797955930233 - val loss: 6.0045166015625 - val mse loss: 0.0031180016230791807
INFO:training log:Time taken for 1 epoch: 2349.501539707184 secs

INFO:training log:Epoch 21/30
INFO:training log:final weights of first 3 elements of batch: [0.03996487 0.04000947 0.04003434 0.04001724 0.04001674 0.03992322
 0.04003646 0.03997511 0.04001737 0.03998922 0.04002532 0.03995149
 0.0400266  0.03997134 0.04000828 0.04001452 0.04003632 0.04002356
 0.03999714 0.04001102 0.04001376 0.03998691 0.03997176 0.03999923
 0.03997872], [0.0398205  0.03997755 0.04008997 0.0400458  0.04006426 0.03984567
 0.0398082  0.03991611 0.04036961 0.04029337 0.04016786 0.04011966
 0.03969276 0.04026112 0.03976027 0.04011461 0.03956813 0.03994359
 0.04006611 0.03995037 0.0400356  0.03994033 0.04018239 0.03994577
 0.0400204 ], [0.04118521 0.03994438 0.03949854 0.03946372 0.04125318 0.03999834
 0.03999859 0.03911955 0.03992467 0.04005581 0.04036723 0.04071754
 0.03919599 0.03962939 0.03862596 0.04033993 0.04008722 0.03981913
 0.04036498 0.03942686 0.03938369 0.04081596 0.04091201 0.0400773
 0.03979481]
INFO:training log:train loss 6.008060455322266 -  train mse loss: 0.0043240077793598175 - val loss: 6.007200241088867 - val mse loss: 0.002881081076338887
INFO:training log:Time taken for 1 epoch: 2409.1001300811768 secs

INFO:training log:Epoch 22/30
INFO:training log:final weights of first 3 elements of batch: [0.03999789 0.03996911 0.04000059 0.0400314  0.04001899 0.0400347
 0.039984   0.04002388 0.03999246 0.03998437 0.04001927 0.03998674
 0.04002159 0.03989923 0.04001837 0.03995117 0.0400268  0.03999862
 0.04000599 0.03999588 0.04003175 0.03996927 0.04002419 0.03999092
 0.04002288], [0.03999745 0.04055715 0.03987562 0.03980622 0.04023671 0.03982778
 0.04032276 0.03976798 0.04035874 0.03992549 0.03983698 0.04037833
 0.03971355 0.03990745 0.03982711 0.03995465 0.0403236  0.03973931
 0.03999379 0.04006328 0.03971482 0.04031697 0.03977967 0.03986586
 0.03990878], [0.04047111 0.04029594 0.03925762 0.03977945 0.04098937 0.04062027
 0.04009507 0.04118495 0.04080265 0.03990367 0.04010025 0.03874715
 0.03984962 0.04056086 0.03968782 0.04016965 0.04080455 0.0397116
 0.03895385 0.04012235 0.03937566 0.04036837 0.04005997 0.03908017
 0.03900806]
INFO:training log:train loss 6.004889488220215 -  train mse loss: 0.004108516965061426 - val loss: 6.0035295486450195 - val mse loss: 0.003041428979486227
INFO:training log:Time taken for 1 epoch: 2405.7859456539154 secs

INFO:training log:Epoch 23/30
INFO:training log:final weights of first 3 elements of batch: [0.04000603 0.04004396 0.0399515  0.04002738 0.04004358 0.03998079
 0.03998766 0.03997762 0.04004828 0.03998334 0.03998748 0.03999548
 0.03999464 0.04004518 0.03990429 0.04000759 0.03995286 0.04000776
 0.04001655 0.04002305 0.03999469 0.03998552 0.03996714 0.04004714
 0.04002051], [0.03954989 0.03995264 0.03979128 0.04015985 0.04003628 0.04025796
 0.04024469 0.03972986 0.03970221 0.0397702  0.04005305 0.04018561
 0.04042291 0.04017342 0.03974195 0.04048447 0.04034304 0.04009332
 0.03986672 0.03995929 0.03973568 0.04004465 0.03984421 0.04003011
 0.03982667], [0.03993803 0.04024218 0.03963168 0.04018499 0.03915016 0.04076557
 0.0402057  0.03934143 0.03999346 0.03963976 0.04115292 0.0401043
 0.04023914 0.04000467 0.04105463 0.03873654 0.04075321 0.03953293
 0.03874243 0.03923405 0.03962161 0.0405293  0.04084827 0.03951544
 0.04083757]
INFO:training log:train loss 6.005154609680176 -  train mse loss: 0.003844756167382002 - val loss: 6.003444194793701 - val mse loss: 0.002939528087154031
INFO:training log:Time taken for 1 epoch: 2400.661523103714 secs

INFO:training log:Epoch 24/30
INFO:training log:final weights of first 3 elements of batch: [0.03998061 0.04000051 0.03992862 0.04003149 0.040027   0.04004838
 0.04002314 0.04001624 0.03994732 0.04002119 0.03996781 0.04002685
 0.03998711 0.04001001 0.04005598 0.03994757 0.03996967 0.04003217
 0.03997061 0.0400145  0.03998393 0.04001258 0.04001926 0.04001087
 0.03996651], [0.03990959 0.03997308 0.03992511 0.03975125 0.04026009 0.03969001
 0.03964937 0.0400499  0.03992741 0.04024891 0.04012723 0.04022754
 0.03973008 0.04014311 0.04027199 0.0398469  0.04036994 0.039415
 0.04000384 0.04018111 0.03995492 0.0402793  0.04023418 0.03976411
 0.04006594], [0.0386042  0.03956144 0.03963366 0.04010592 0.03925496 0.03939023
 0.04070826 0.04150749 0.0398976  0.03974455 0.04054754 0.04000222
 0.03974612 0.03848805 0.0409308  0.04047819 0.04048738 0.0404736
 0.03950084 0.04058732 0.040462   0.04153505 0.03989139 0.03960336
 0.03885783]
INFO:training log:train loss 6.005058765411377 -  train mse loss: 0.004046711605042219 - val loss: 6.005538463592529 - val mse loss: 0.0028734931256622076
INFO:training log:Time taken for 1 epoch: 2399.64368724823 secs

INFO:training log:Epoch 25/30
INFO:training log:final weights of first 3 elements of batch: [0.04000555 0.03998001 0.03998709 0.04002028 0.03991255 0.03998969
 0.04001983 0.03998993 0.04002551 0.040038   0.0400186  0.04001707
 0.04003171 0.03996202 0.04000512 0.04002091 0.04002052 0.03996078
 0.03998255 0.03999799 0.03995845 0.04002105 0.03997636 0.04002424
 0.04003416], [0.04009111 0.03969067 0.03987163 0.03972553 0.04053599 0.03964173
 0.04028151 0.03951149 0.04023402 0.04010235 0.03981895 0.04062087
 0.04025501 0.03978265 0.03991094 0.04026793 0.03949559 0.03995307
 0.04009759 0.03997031 0.03988034 0.03995929 0.04001641 0.04029426
 0.03999076], [0.03940663 0.04000332 0.04078463 0.04099409 0.04124702 0.03934423
 0.04054058 0.03995183 0.03897092 0.03947821 0.0409376  0.03980027
 0.03951851 0.04001451 0.03984074 0.03973436 0.03934579 0.03979943
 0.0409119  0.03936885 0.0400429  0.04108606 0.04039618 0.04019356
 0.03828787]
INFO:training log:train loss 5.999602794647217 -  train mse loss: 0.003915397450327873 - val loss: 6.000139236450195 - val mse loss: 0.0029933869373053312
INFO:training log:Time taken for 1 epoch: 2406.6296451091766 secs

INFO:training log:Epoch 26/30
INFO:training log:final weights of first 3 elements of batch: [0.04000361 0.04003156 0.03998829 0.04001361 0.0400236  0.03999929
 0.0400289  0.04002886 0.03999722 0.04002967 0.03998223 0.03994563
 0.03999082 0.04002587 0.0400104  0.03996161 0.0399887  0.04002481
 0.04001382 0.03996303 0.03999715 0.04000348 0.03997138 0.03995769
 0.04001874], [0.04006301 0.04016111 0.03978192 0.03995573 0.040132   0.04010309
 0.03946307 0.04004342 0.03995702 0.04016378 0.04001049 0.03973781
 0.04022505 0.03975031 0.040018   0.0398313  0.03986703 0.03997121
 0.04019556 0.0396275  0.04033833 0.04000593 0.04000142 0.03984412
 0.04075177], [0.03940379 0.04092319 0.0400472  0.04039071 0.04071825 0.03995612
 0.04052168 0.0402474  0.03994434 0.03953636 0.03991635 0.03984476
 0.03969108 0.03877665 0.03966818 0.04068972 0.04099618 0.04016963
 0.0404244  0.03893524 0.03974042 0.0395923  0.03961802 0.04007424
 0.04017384]
INFO:training log:train loss 6.004859447479248 -  train mse loss: 0.003949073143303394 - val loss: 6.00555419921875 - val mse loss: 0.0028402910102158785
INFO:training log:Time taken for 1 epoch: 2401.1282303333282 secs

INFO:training log:Epoch 27/30
INFO:training log:final weights of first 3 elements of batch: [0.04002424 0.04002113 0.03986657 0.04000172 0.04000348 0.0399659
 0.03999176 0.04002094 0.04002915 0.03997026 0.04003154 0.04003189
 0.04003349 0.03997828 0.0399537  0.040036   0.04001828 0.0399804
 0.0399963  0.03999462 0.04001624 0.04002753 0.04002151 0.0399583
 0.04002677], [0.04012945 0.04039906 0.0397954  0.03967639 0.03938628 0.04016649
 0.04028368 0.04015007 0.03973357 0.03965342 0.03988731 0.04029351
 0.04025953 0.04002367 0.03999429 0.03982782 0.04011765 0.03997648
 0.04011741 0.03985887 0.04046212 0.03960733 0.04019585 0.04003607
 0.03996832], [0.03996825 0.04007145 0.03960145 0.0391991  0.03972555 0.04096514
 0.04079926 0.04036149 0.04043667 0.03968337 0.03934899 0.03867036
 0.03976008 0.03925449 0.04098775 0.03954755 0.04054007 0.03972561
 0.04016061 0.04070939 0.04018638 0.0402897  0.04106257 0.03910647
 0.03983827]
INFO:training log:train loss 5.999680995941162 -  train mse loss: 0.0036604797933250666 - val loss: 6.003142833709717 - val mse loss: 0.002885925816372037
INFO:training log:Time taken for 1 epoch: 2398.720340490341 secs

INFO:training log:Epoch 28/30
INFO:training log:final weights of first 3 elements of batch: [0.04001318 0.04002922 0.03999957 0.04002481 0.0399927  0.04001553
 0.03998392 0.04002951 0.03998887 0.04001868 0.03999003 0.04001563
 0.04002431 0.0400026  0.04002765 0.03994048 0.0400175  0.03998327
 0.04003764 0.04004257 0.03994958 0.03997235 0.03996964 0.03996428
 0.03996642], [0.03988857 0.03981901 0.04044207 0.04034699 0.04013257 0.04011947
 0.03978225 0.03958822 0.04004053 0.04041897 0.04037067 0.03963043
 0.03963867 0.03966958 0.04002079 0.04016856 0.03988552 0.04012285
 0.03937884 0.03980305 0.04017075 0.04047064 0.03975129 0.04010991
 0.04022985], [0.04033776 0.03998321 0.04057663 0.03976804 0.03874064 0.041609
 0.03930929 0.04052542 0.03864581 0.03944641 0.03994506 0.04046352
 0.04087795 0.04032457 0.03915227 0.03971612 0.03885323 0.04016487
 0.04012576 0.04149045 0.04006309 0.03906497 0.03970676 0.04004911
 0.04106004]
INFO:training log:train loss 6.005776405334473 -  train mse loss: 0.0037868276704102755 - val loss: 6.003812789916992 - val mse loss: 0.0027531071100383997
INFO:training log:Time taken for 1 epoch: 2399.442931652069 secs

INFO:training log:Epoch 29/30
INFO:training log:final weights of first 3 elements of batch: [0.03997308 0.04003218 0.04000849 0.04000013 0.03997196 0.03997592
 0.04002195 0.04002689 0.04001149 0.04003782 0.03999737 0.04000906
 0.04001661 0.04000368 0.04002905 0.03994692 0.04000043 0.03997838
 0.0399467  0.03998825 0.04001053 0.03999375 0.04002173 0.03998847
 0.04000918], [0.0396105  0.0400197  0.03983075 0.04039563 0.03988903 0.0400719
 0.03988257 0.03989721 0.03992232 0.04027147 0.03999935 0.04028709
 0.04004471 0.03933449 0.0402404  0.04013042 0.03981235 0.04008187
 0.04040052 0.04018602 0.03972033 0.04004629 0.03969004 0.04015284
 0.04008215], [0.04002627 0.04032854 0.03983079 0.03967107 0.04094418 0.04018
 0.0396371  0.03916743 0.04000534 0.04066655 0.03953709 0.03964082
 0.03989077 0.0406188  0.04039478 0.03943903 0.03975364 0.03889776
 0.04060269 0.04044718 0.04039359 0.03909729 0.04021447 0.0404508
 0.04016401]
INFO:training log:train loss 6.006535530090332 -  train mse loss: 0.0035627514589577913 - val loss: 6.005110740661621 - val mse loss: 0.0029003687668591738
INFO:training log:Time taken for 1 epoch: 2409.210131883621 secs

INFO:training log:Epoch 30/30
INFO:training log:final weights of first 3 elements of batch: [0.03991626 0.04001442 0.04001498 0.04000904 0.03997988 0.04003134
 0.04003292 0.03999501 0.03996048 0.03998468 0.03999817 0.03990912
 0.0399886  0.04000601 0.04004101 0.04004226 0.03996891 0.04002504
 0.03998328 0.04001809 0.0400052  0.04003875 0.03999526 0.04002099
 0.04002029], [0.03980536 0.03980616 0.03982491 0.03989282 0.03978613 0.04010835
 0.03962217 0.03999203 0.0401817  0.03983402 0.03990104 0.04024919
 0.04002386 0.0400994  0.04022547 0.0399391  0.04011242 0.040039
 0.04024165 0.03960345 0.04014419 0.04024763 0.03961861 0.04064957
 0.04005175], [0.03916284 0.03980528 0.04000698 0.0403804  0.0400424  0.0399016
 0.03930333 0.03924995 0.03964518 0.04102119 0.03964338 0.03941254
 0.0401977  0.04089449 0.04022813 0.04032426 0.04041374 0.04071161
 0.03947871 0.04154134 0.0409456  0.03921001 0.03984566 0.03964929
 0.03898439]
INFO:training log:train loss 6.006997108459473 -  train mse loss: 0.0038521636743098497 - val loss: 6.0048394203186035 - val mse loss: 0.0027206698432564735
INFO:training log:Time taken for 1 epoch: 2413.9789803028107 secs

INFO:training log:total training time for 30 epochs:71962.03542900085
INFO:training log:saving loss and metrics information...
INFO:training log:saving model output in .npy files...
INFO:training log:training of SMC Transformer for a time-series dataset done...
INFO:training log:>>>--------------------------------------------------------------------------------------------------------------------------------------------------------------<<<
