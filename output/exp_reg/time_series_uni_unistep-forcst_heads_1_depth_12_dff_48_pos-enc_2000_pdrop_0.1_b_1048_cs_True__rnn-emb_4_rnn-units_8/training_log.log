INFO:training log:saving loss and metrics information...
INFO:training log:Training time for 10 epochs: 162.03807425498962
INFO:training log:training of a RNN Baseline for a timeseries dataset done...
INFO:training log:>>>--------------------------------------------------------------------------------------------------------------------------------------------------------------<<<
INFO:training log:model hyperparameters from the config file: {'num_layers': 1, 'num_heads': 1, 'd_model': 12, 'dff': 48, 'rate': 0.1, 'maximum_position_encoding_baseline': 2000, 'maximum_position_encoding_smc': 2000}
INFO:training log:smc hyperparameters from the config file: {'num_particles': 1, 'noise_encoder': 'False', 'noise_SMC_layer': 'True', 'sigma': 0.05}
INFO:training log:GRU model hparams from the config file: {'rnn_bs': 256, 'rnn_emb_dim': 4, 'rnn_units': 8}
INFO:training log:training the baseline Transformer on a time-series dataset...
INFO:training log:number of training samples: 336290
INFO:training log:steps per epoch:320
INFO:training log:training a baseline transformer with positional encoding...
INFO:training log:Epoch 1/10
INFO:training log:saving loss and metrics information...
INFO:training log:Training time for 10 epochs: 125.1755440235138
INFO:training log:training of a RNN Baseline for a timeseries dataset done...
INFO:training log:>>>--------------------------------------------------------------------------------------------------------------------------------------------------------------<<<
INFO:training log:model hyperparameters from the config file: {'num_layers': 1, 'num_heads': 1, 'd_model': 12, 'dff': 48, 'rate': 0.1, 'maximum_position_encoding_baseline': 2000, 'maximum_position_encoding_smc': 2000}
INFO:training log:smc hyperparameters from the config file: {'num_particles': 1, 'noise_encoder': 'False', 'noise_SMC_layer': 'True', 'sigma': 0.05}
INFO:training log:GRU model hparams from the config file: {'rnn_bs': 256, 'rnn_emb_dim': 4, 'rnn_units': 8}
INFO:training log:training the baseline Transformer on a time-series dataset...
INFO:training log:number of training samples: 336290
INFO:training log:steps per epoch:320
INFO:training log:training a baseline transformer with positional encoding...
INFO:training log:Epoch 1/10
WARNING:tensorflow:Layer transformer is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

INFO:training log:train loss 0.43997129797935486
INFO:training log:Time taken for 1 epoch: 73.48017287254333 secs

INFO:training log:Epoch 2/10
INFO:training log:train loss 0.1344408392906189
INFO:training log:Time taken for 1 epoch: 84.0069670677185 secs

INFO:training log:Epoch 3/10
INFO:training log:train loss 0.10211098194122314
INFO:training log:Time taken for 1 epoch: 69.39834499359131 secs

INFO:training log:Epoch 4/10
INFO:training log:train loss 0.08913902193307877
INFO:training log:Time taken for 1 epoch: 91.3856987953186 secs

INFO:training log:Epoch 5/10
INFO:training log:train loss 0.07758580893278122
INFO:training log:Time taken for 1 epoch: 113.08395600318909 secs

INFO:training log:Epoch 6/10
INFO:training log:train loss 0.06960710883140564
INFO:training log:Time taken for 1 epoch: 138.9555368423462 secs

INFO:training log:Epoch 7/10
INFO:training log:train loss 0.06579634547233582
INFO:training log:Time taken for 1 epoch: 87.00338315963745 secs

INFO:training log:Epoch 8/10
INFO:training log:train loss 0.06267885863780975
INFO:training log:Time taken for 1 epoch: 71.7609531879425 secs

INFO:training log:Epoch 9/10
INFO:training log:train loss 0.0593915618956089
INFO:training log:Time taken for 1 epoch: 76.58502006530762 secs

INFO:training log:Epoch 10/10
INFO:training log:train loss 0.05694324150681496
INFO:training log:Time taken for 1 epoch: 84.21771025657654 secs

INFO:training log:total training time for 10 epochs:889.8828799724579
INFO:training log:saving loss and metrics information...
